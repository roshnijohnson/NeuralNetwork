# -*- coding: utf-8 -*-
"""ML_ASSIGNMENT_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1udpg1mVyXcUcPv82tgmXJppdrXNeDHpA

CS 6375 Assignment-2 : Neural Network

Name of students:

Vaibhav Tyagi - VXT200018

Roshni Johnson Nambiaparambil - RXN200022
"""

import numpy as np
import pandas as pd

dff = pd.read_csv("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv", sep=';')

dff.info()

dff.columns

#####################################################################################################################
#   Assignment 2: Neural Network Analysis
#   This is a starter code iazn Python 3.6 for a neural network.
#   You need to have numpy and pandas installed before running this code.
#   You need to complete all TODO marked sections
#   You are free to modify this code in any way you want, but need to mention it
#   in the README file.
#
#####################################################################################################################


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from keras.models import Sequential
from keras.layers import Dense
from tensorflow.keras.optimizers import Adam


class NeuralNet:
    def __init__(self, dataFile, header=True):
        self.raw_input = pd.read_csv(dataFile, sep=';')

    # TODO: Write code for pre-processing the dataset, which would include
    # standardization, normalization,
    #   categorical to numerical, etc
    def preprocess(self):
        self.processed_data = self.raw_input

        # checking for null values
        if self.raw_input.isnull().values.any() == False:
          print("No Null Values.")

        # standardization
        sc = StandardScaler()
        self.processed_data = sc.fit_transform(self.processed_data)

        self.processed_data = pd.DataFrame(self.processed_data, columns=self.raw_input.columns)

        # print(self.processed_data.head())

        return 0

    # TODO: Train and evaluate models for all combinations of parameters
    # specified in the init method. We would like to obtain following outputs:
    #   1. Training Accuracy and Error (Loss) for every model
    #   2. Test Accuracy and Error (Loss) for every model
    #   3. History Curve (Plot of Accuracy against training steps) for all
    #       the models in a single plot. The plot should be color coded i.e.
    #       different color for each model


    def train_evaluate(self):
        ncols = len(self.processed_data.columns)
        nrows = len(self.processed_data.index)
        X = self.raw_input.iloc[:, 0:(ncols - 1)]
        y = self.raw_input.iloc[:, (ncols-1)]
        print(y)
        X_train, X_test, y_train, y_test = train_test_split(X, y)

        # Below are the hyperparameters that you need to use for model
        #   evaluation
        activations = ['sigmoid', 'tanh', 'relu']
        learning_rate = [0.01, 0.1]
        max_iterations = [100, 200] # also known as epochs
        num_hidden_layers = [2, 3]

        for ac in activations:
          for lr in learning_rate:
            for hiddenlayer in num_hidden_layers:
              for epoch in max_iterations:

                  # Create the neural network and be sure to keep track of the performance
                  # metrics
                  model = Sequential()
                  model.add(tf.keras.layers.Flatten())
                  # add input layer and hidden layer
                  # model.add(Dense(2, input_shape=(3,), activation='relu'))
                  # input - 11
                  for i in range(hiddenlayer):
                    model.add(Dense(128, input_dim=11, activation=ac))


                  #o/p layer
                  model.add(Dense(11, activation='softmax'))


                  # model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
                  model.compile(optimizer=Adam(learning_rate=lr), loss='sparse_categorical_crossentropy', metrics=['accuracy'])

                  history = model.fit(X_train, y_train, epochs=epoch)

                  train_mse = model.evaluate(X_train, y_train)
                  test_mse = model.evaluate(X_test, y_test)

                  print("test Accuracy", test_mse)
                  print("train Accuracy", train_mse)

                  # Plot the model history for each model in a single plot
                  # model history is a plot of accuracy vs number of epochs
                  # you may want to create a large sized plot to show multiple lines
                  # in a same figure.

                  plt.figure(figsize=(12,8))
                  plot_title = "Accuracy Score vs Epoch Plot for Activation='{}', Learning Rate={}, Num_Hidden_Layers={}, Epochs={}".format(ac, lr, hiddenlayer, epoch)
                  plt.title(plot_title)
                  plt.plot(history.history['accuracy'])
                  plt.xlabel("Epochs")
                  plt.ylabel("Model Accuracy")
                  plt.legend()
                  plt.show()


if __name__ == "__main__":
    neural_network = NeuralNet("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv") # put in path to your file
    neural_network.preprocess()
    neural_network.train_evaluate()